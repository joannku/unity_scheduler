{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT TIME: 2024-10-17 21:07:53\n",
      "# Clearing old backups.\n",
      "    Starting to scan /data/jkuc/unity_scheduler/data/backup...\n",
      "    Scanning folder: /data/jkuc/unity_scheduler/data/backup\n",
      "    Scanning folder: /data/jkuc/unity_scheduler/data/backup/3_email_templates\n",
      "    Scanning folder: /data/jkuc/unity_scheduler/data/backup/4_email_log\n",
      "    Scanning folder: /data/jkuc/unity_scheduler/data/backup/2_email_schedule\n",
      "    Scanning folder: /data/jkuc/unity_scheduler/data/backup/1_visit_schedule\n",
      "    > Finished scanning /data/jkuc/unity_scheduler/data/backup.\n",
      "# Backing up local CSVs.\n",
      "    No changes detected in 4_email_log.csv, skipping backup.\n",
      "    * Backed up 3_email_templates.csv.\n",
      "    No changes detected in 2_email_schedule.csv, skipping backup.\n",
      "    No changes detected in 1_visit_schedule.csv, skipping backup.\n",
      "    > Backup complete.\n",
      "# Checking for changes between local and streamlit files.\n",
      "    No updates in 1_visit_schedule.csv.\n",
      "    ! Changes detected in 3_email_templates.csv.\n",
      "    * Updated 3_email_templates.csv.\n",
      "    > Check for changes completed.\n",
      "# Checking for missing schedules.\n",
      "    > No missing schedules found.\n",
      "# Checking for emails to be sent today.\n",
      "    > Found 4 emails to send today.\n",
      "        Participant Testing scheduled to receive email BOT01 today.\n",
      "        Participant Testing scheduled to receive email UNITY01 today.\n",
      "        Participant NewUser scheduled to receive email BOT01 today.\n",
      "        Participant NewUser scheduled to receive email UNITY01 today.\n",
      "        Email BOT01 for participant Testing was already sent. Skipping.\n",
      "        Email UNITY01 for participant Testing was already sent. Skipping.\n",
      "        Email BOT01 for participant NewUser was already sent. Skipping.\n",
      "        Email UNITY01 for participant NewUser was already sent. Skipping.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import filecmp\n",
    "import csv\n",
    "import webbrowser\n",
    "from datetime import datetime, timedelta\n",
    "from O365 import Account, FileSystemTokenBackend, Message\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import time\n",
    "import numpy as np\n",
    "import textwrap\n",
    "\n",
    "class OutlookEmailer:\n",
    "\n",
    "    def __init__(self, creds_path):\n",
    "        \"\"\"\n",
    "        Initialize the OutlookEmailer by loading credentials from the given file.\n",
    "        \n",
    "        :param creds_path: Path to the credentials JSON file.\n",
    "        \"\"\"\n",
    "        self.creds_dict = self._load_creds(creds_path)\n",
    "\n",
    "    def _load_creds(self, path):\n",
    "        \"\"\"\n",
    "        Load credentials from the provided file path.\n",
    "        \n",
    "        :param path: Path to the credentials JSON file.\n",
    "        :return: A dictionary containing the credentials.\n",
    "        \"\"\"\n",
    "        with open(path) as file:\n",
    "            creds_data = json.load(file)\n",
    "\n",
    "        return {\n",
    "            'description': creds_data[\"outlook_description\"],\n",
    "            'client_secret': creds_data[\"outlook_client_secret\"],\n",
    "            'application_id': creds_data[\"outlook_application_id\"],\n",
    "            'shared_mailbox': creds_data[\"outlook_shared_mailbox\"],\n",
    "            'personal_mailbox': creds_data[\"outlook_personal_mailbox\"],\n",
    "            'tenant_id': creds_data[\"outlook_tenant_id\"]\n",
    "        }\n",
    "    \n",
    "    def _fold_lines(self, ics_content):\n",
    "        \"\"\"\n",
    "        Fold long lines according to ICS file format rules.\n",
    "        Lines longer than 75 characters should be wrapped with a space on the following line.\n",
    "        \"\"\"\n",
    "        lines = ics_content.splitlines()\n",
    "        folded_lines = []\n",
    "        \n",
    "        for line in lines:\n",
    "            while len(line) > 75:\n",
    "                # Split the line at 75 characters and fold it to the next line\n",
    "                folded_lines.append(line[:75])\n",
    "                line = ' ' + line[75:]\n",
    "            folded_lines.append(line)\n",
    "        \n",
    "        return '\\r\\n'.join(folded_lines)\n",
    "\n",
    "\n",
    "    def get_creds(self, creds_file_path):\n",
    "        \"\"\"\n",
    "        Get credentials by loading them from a specified path.\n",
    "        \n",
    "        :param creds_file_path: Path to the credentials JSON file.\n",
    "        :return: A dictionary containing the credentials.\n",
    "        \"\"\"\n",
    "        return self._load_creds(creds_file_path)\n",
    "\n",
    "    def load_attachments(self, folder_path='attachments'):\n",
    "        files = os.listdir(folder_path)\n",
    "        return {os.path.splitext(file)[0]: os.path.join(folder_path, file) for file in files}\n",
    "\n",
    "    def authenticate_outlook(self, mailbox='personal'):\n",
    "        credentials = (self.creds_dict['application_id'], self.creds_dict['client_secret'])\n",
    "        token_backend = FileSystemTokenBackend(token_path='.', token_filename='o365_token.txt')\n",
    "\n",
    "        # Determine which mailbox to use\n",
    "        if mailbox == 'shared':\n",
    "            main_resource = self.creds_dict['shared_mailbox']\n",
    "        else:\n",
    "            main_resource = self.creds_dict['personal_mailbox']\n",
    "        \n",
    "        # Create an Account object with the chosen mailbox\n",
    "        account = Account(credentials, token_backend=token_backend, main_resource=main_resource)\n",
    "\n",
    "        # Add 'Mail.Send' to the scopes\n",
    "        scopes = ['User.Read', 'Mail.Read', 'Mail.Send', 'Mail.Read.Shared', 'Mail.Send.Shared']\n",
    "\n",
    "        # Try to load the token from the file\n",
    "        if not account.is_authenticated:\n",
    "            # Get the authorization URL\n",
    "            url, _ = account.con.get_authorization_url(requested_scopes=scopes)\n",
    "\n",
    "            # Open the URL in a web browser\n",
    "            webbrowser.open(url)\n",
    "\n",
    "            # Prompt the user to manually copy the authentication URL\n",
    "            print(\"Please manually copy the authentication URL from the web browser and paste it below.\")\n",
    "            auth_url = input(\"Authentication URL: \")\n",
    "\n",
    "            # Authenticate with the provided URL and scopes\n",
    "            if account.authenticate(url=auth_url, scopes=scopes):\n",
    "                # Save the token to the file\n",
    "                \"Authentication successful. Token saved to 'o365_token.txt'.\"\n",
    "            else:\n",
    "                print(\"Authentication failed.\")\n",
    "                return None\n",
    "\n",
    "        return account\n",
    "\n",
    "\n",
    "    def send_email_from_outlook(self, sender, recepients, subject, email_body, attachments_paths, code=None):\n",
    "\n",
    "        account = self.authenticate_outlook(self.creds_dict)\n",
    "\n",
    "        if account is not None and account.is_authenticated:\n",
    "            print('Outlook email authentication successful.')\n",
    "\n",
    "            m = account.new_message()\n",
    "            m.sender.address = sender  # The shared mailbox\n",
    "            m.to.add(recepients)\n",
    "            m.subject = subject\n",
    "\n",
    "            # Check if attachments_paths is not None\n",
    "            if attachments_paths is not None:\n",
    "                # Loop over attachments paths\n",
    "                for path in attachments_paths:\n",
    "                    # Skip over None values\n",
    "                    if path is not None:\n",
    "                        # Add the attachment\n",
    "                        m.attachments.add(path)\n",
    "\n",
    "            m.body = email_body\n",
    "            m.send()\n",
    "\n",
    "            print(f\"Email {code} from {sender} to {recepients} sent successfully!\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Failed to send email. Authentication unsuccessful.\")\n",
    "            return False\n",
    "\n",
    "        #TODO: Figure out when authentication expires, and how to make it last longer?\n",
    "\n",
    "    def create_ics_attachment(self, subject, description, start_time, end_time, location):\n",
    "        # Generate the ICS content as a string\n",
    "        ics_content = textwrap.dedent(f\"\"\"\\\n",
    "    BEGIN:VCALENDAR\n",
    "    VERSION:2.0\n",
    "    PRODID:-//Your Organization//NONSGML v1.0//EN\n",
    "    BEGIN:VEVENT\n",
    "    UID:{datetime.now().strftime('%Y%m%dT%H%M%SZ')}\n",
    "    DTSTAMP:{datetime.now().strftime('%Y%m%dT%H%M%SZ')}\n",
    "    DTSTART:{start_time.strftime('%Y%m%dT%H%M%SZ')}\n",
    "    DTEND:{end_time.strftime('%Y%m%dT%H%M%SZ')}\n",
    "    SUMMARY:{subject}\n",
    "    DESCRIPTION:{description}\n",
    "    LOCATION:{location}\n",
    "    END:VEVENT\n",
    "    END:VCALENDAR\n",
    "    \"\"\")\n",
    "\n",
    "        # Ensure lines don't exceed 75 characters for ICS format\n",
    "        ics_content = self._fold_lines(ics_content)\n",
    "\n",
    "        # Write ICS content to a file\n",
    "        ics_file_path = \"calendarInvite.ics\"\n",
    "        with open(ics_file_path, 'w') as f:\n",
    "            f.write(ics_content)\n",
    "\n",
    "        return ics_file_path\n",
    "\n",
    "    \n",
    "    def is_valid_email(self, email):\n",
    "        email = email.lower()  \n",
    "        email_regex = r'^\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b$'\n",
    "        return re.match(email_regex, email) is not None\n",
    "    \n",
    "\n",
    "    def get_email_template(self, email_code, templates_df):\n",
    "        mask = templates_df[\"EmailCode\"].astype(str) == email_code\n",
    "        email_body = templates_df[mask]['EmailBody'].iloc[0]\n",
    "        subject = templates_df[mask]['Subject'].iloc[0]\n",
    "        escaped_email_body = re.sub(r\"{(?!\\w)\", \"{{\", email_body)\n",
    "        escaped_email_body = re.sub(r\"(?<=\\W)}\", \"}}\", escaped_email_body)\n",
    "        return subject, escaped_email_body\n",
    "\n",
    "    def send_reminders(self, email_list, email_code, templates_df):\n",
    "        if not email_list:\n",
    "            return\n",
    "\n",
    "        subject, email_body = self.get_email_template(email_code, templates_df)\n",
    "        \n",
    "        for email in email_list:\n",
    "            self.send_email_from_outlook(self.creds_dict, SENDER_EMAIL, [email], subject, email_body, attachments_paths=None, code=email_code)\n",
    "            self.google_sheet.attempt_request(self.google_sheet.update_column_value, 'Journalling Sign Ups', 5, \"Email\", email)\n",
    "            self.google_sheet.attempt_request(self.google_sheet.update_column_value, 'Journalling Sign Ups', 5, \"EmailCode\", email_code)\n",
    "            self.google_sheet.attempt_request(self.google_sheet.update_column_value, 'Journalling Sign Ups', 5, \"SentAt\", str(dt.datetime.now()))\n",
    "\n",
    "    def generate_src_tag(self, file_paths):\n",
    "        src_tags = {}\n",
    "        \n",
    "        for file_path in file_paths:\n",
    "            # Encode the image in base64\n",
    "            encoded_image = self.encode_image_base64(file_path)\n",
    "            \n",
    "            # Extract the file extension (without the dot)\n",
    "            file_extension = os.path.splitext(file_path)[1][1:]\n",
    "            \n",
    "            # Generate the filename (without the extension)\n",
    "            filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "            \n",
    "            # Generate the src tag\n",
    "            src_tag = f'<img src=\"data:image/{file_extension};base64,{encoded_image}\" alt=\"{filename} Image\" width=\"200\">'\n",
    "            \n",
    "            # Append the src tag to the dictionary\n",
    "            src_tags[filename] = src_tag\n",
    "        \n",
    "        return src_tags\n",
    "\n",
    "    def encode_image_base64(image_path):\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "        return encoded_string\n",
    "    \n",
    "\n",
    "    def find_file_with_extension(self, directory, filename_prefix):\n",
    "        # List all files in the given directory\n",
    "        files = os.listdir(directory)\n",
    "        \n",
    "        # Search for a file that starts with the given filename_prefix\n",
    "        for file in files:\n",
    "            if file.startswith(filename_prefix):\n",
    "                return file  # return the full filename including its extension\n",
    "        return None  # return None if no matching file was found\n",
    "\n",
    "    def read_emails_from_outlook(self, folder_name='Inbox', query=None, limit=10, mailbox='personal'):\n",
    "    # Authenticate with the specified mailbox\n",
    "        account = self.authenticate_outlook(mailbox=mailbox)\n",
    "        if not account or not account.is_authenticated:\n",
    "            print(\"! Failed to authenticate Outlook account for reading emails.\")\n",
    "            return None\n",
    "\n",
    "        # Get the mailbox\n",
    "        if mailbox == 'personal':\n",
    "            mailbox = self.creds_dict[\"personal_mailbox\"]\n",
    "        elif mailbox == 'shared':\n",
    "            mailbox = self.creds_dict[\"shared_mailbox\"]\n",
    "\n",
    "        mailbox = account.mailbox(mailbox)\n",
    "\n",
    "        # Get the folder to read emails from (default is 'Inbox')\n",
    "        folder = mailbox.get_folder(folder_name) if folder_name != 'Inbox' else mailbox.inbox_folder()\n",
    "\n",
    "        # Query emails\n",
    "        try:\n",
    "            emails = folder.get_messages(limit=limit, query=query)\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving emails: {e}\")\n",
    "            return None\n",
    "\n",
    "        email_data = []\n",
    "        for message in emails:\n",
    "            email_info = {\n",
    "                'subject': message.subject,\n",
    "                'from': message.sender.address,\n",
    "                'to': [recipient.address for recipient in message.to],\n",
    "                'received': message.received,\n",
    "                'body': message.body,\n",
    "                'attachments': [attachment.name for attachment in message.attachments]\n",
    "            }\n",
    "            email_data.append(email_info)\n",
    "\n",
    "            # Attempt to mark emails as read\n",
    "            # try:\n",
    "            #     message.mark_as_read()\n",
    "            # except Exception as e:\n",
    "            #     print(f\"Error marking message as read (message subject: {message.subject}): {e}\")  # Print the specific error encountered\n",
    "            #     continue\n",
    "\n",
    "        return email_data\n",
    "\n",
    "class Scheduler:\n",
    "\n",
    "    def __init__(self, paths, backup_limit=60, overwrite_local=True):\n",
    "\n",
    "        self.paths = self.__load_paths(paths)\n",
    "        self.__reload_dfs()\n",
    "        \n",
    "        self.local_dir = self.paths['local_dir']\n",
    "        self.backup_dir = self.paths['backup_dir']\n",
    "        self.log_file = self.paths['log_file']\n",
    "\n",
    "        self.missing_schedule_checked = False\n",
    "        \n",
    "        self.emailer = OutlookEmailer(self.paths['creds'])\n",
    "\n",
    "        self.date_time_now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        self.date_time_now_fileformat = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        self.backup_limit = backup_limit\n",
    "        self.overwrite_local = overwrite_local\n",
    "        \n",
    "        self.dates = ['V1_Date', 'V2_Date', 'V3_Date', 'V4_Date', 'V5_Date', 'V6_Date', 'V7_Date']\n",
    "        self.times = ['V1_Time', 'V2_Time', 'V3_Time', 'V4_Time', 'V5_Time', 'V6_Time', 'V7_Time']\n",
    "\n",
    "        logging.basicConfig(\n",
    "            filename=self.log_file, \n",
    "            level=logging.INFO, \n",
    "            format='%(asctime)s - %(levelname)s - %(message)s', \n",
    "            datefmt='%Y-%m-%d %H:%M:%S'\n",
    "        )\n",
    "\n",
    "        # load dataframes\n",
    "    \n",
    "    def __reload_dfs(self):\n",
    "        # local\n",
    "        self.df_vs_l = pd.read_csv(self.paths['visit_schedule_local'])\n",
    "        self.df_es_l = pd.read_csv(self.paths['email_schedule_local'])\n",
    "        self.df_et_l = pd.read_csv(self.paths['email_templates_local'])\n",
    "        self.df_el_l = pd.read_csv(self.paths['email_log_local'])\n",
    "        # streamlit\n",
    "        self.df_vs_s = pd.read_csv(self.paths['visit_schedule_streamlit'])\n",
    "        self.df_et_s = pd.read_csv(self.paths['email_templates_streamlit'])\n",
    "    \n",
    "    def __load_paths(self, paths):\n",
    "        with open(paths, 'r') as f:\n",
    "            paths = json.load(f)\n",
    "        return paths\n",
    "\n",
    "    def backup_local_csvs(self):\n",
    "        print(\"# Backing up local CSVs.\")\n",
    "        if not os.path.exists(self.backup_dir):\n",
    "            os.makedirs(self.backup_dir)\n",
    "            \n",
    "        log_details = []\n",
    "        \n",
    "        for filename in os.listdir(self.local_dir):\n",
    "            if filename.endswith('.csv'):\n",
    "                subfolder_name = filename.rsplit('.', 1)[0]\n",
    "                subfolder_path = os.path.join(self.backup_dir, subfolder_name)\n",
    "                \n",
    "                if not os.path.exists(subfolder_path):\n",
    "                    os.makedirs(subfolder_path)\n",
    "\n",
    "                source_file_path = os.path.join(self.local_dir, filename)\n",
    "\n",
    "                # Get the most recent backup file in the subfolder (if any)\n",
    "                existing_backups = [f for f in os.listdir(subfolder_path) if f.endswith('.csv')]\n",
    "                existing_backups.sort(reverse=True)  # Sort backups by date\n",
    "\n",
    "                most_recent_backup = existing_backups[0] if existing_backups else None\n",
    "                most_recent_backup_path = os.path.join(subfolder_path, most_recent_backup) if most_recent_backup else None\n",
    "\n",
    "                # Compare the current file with the most recent backup (if any)\n",
    "                if most_recent_backup_path and filecmp.cmp(source_file_path, most_recent_backup_path, shallow=False):\n",
    "                    log_details.append(f\"    No changes detected in {filename}, skipping backup.\")\n",
    "                else:\n",
    "                    backup_filename = f\"{subfolder_name}_{self.date_time_now_fileformat}.csv\"\n",
    "                    backup_file_path = os.path.join(subfolder_path, backup_filename)\n",
    "                    if self.overwrite_local:\n",
    "                        shutil.copy2(source_file_path, backup_file_path)\n",
    "                    log_details.append(f\"    * Backed up {filename}.\")\n",
    "\n",
    "        # Write log details to the log file\n",
    "        with open(self.log_file, 'a') as log:\n",
    "            for detail in log_details:\n",
    "                log.write(detail + '\\n')\n",
    "                print(detail)\n",
    "        \n",
    "        print('    > Backup complete.')\n",
    "\n",
    "    def clear_old_backups(self):\n",
    "        print(\"# Clearing old backups.\")\n",
    "        print(f\"    Starting to scan {self.backup_dir}...\")  # Debugging print\n",
    "        pattern = re.compile(r\"(\\d{8})_(\\d{6})\\.csv$\")\n",
    "        for foldername, _, filenames in os.walk(self.backup_dir):\n",
    "            print(f\"    Scanning folder: {foldername}\")  # Debugging print\n",
    "            for filename in filenames:\n",
    "                match = pattern.search(filename)\n",
    "                if not match:\n",
    "                    print(f\"    Skipping: {filename}\")  # Debugging print for filenames that don't match the pattern\n",
    "                    continue\n",
    "                \n",
    "                date_str, time_str = match.groups()\n",
    "                \n",
    "                # Convert date and time strings to a datetime object\n",
    "                file_date = datetime.strptime(date_str + time_str, \"%Y%m%d%H%M%S\")\n",
    "                self.dtm = datetime.strptime(self.date_time_now_fileformat, \"%Y%m%d_%H%M%S\")\n",
    "                \n",
    "                # Check file age\n",
    "                if self.backup_limit == 0:\n",
    "                    # remove all files\n",
    "                    file_path = os.path.join(foldername, filename)\n",
    "                    try:\n",
    "                        os.remove(file_path)\n",
    "                        print(f\"    Removed {file_path}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"    Unable to remove {file_path}. Reason: {e}\")\n",
    "                elif (self.dtm - file_date).days > self.backup_limit:\n",
    "                    file_path = os.path.join(foldername, filename)\n",
    "                    try:\n",
    "                        os.remove(file_path)\n",
    "                        print(f\"    Removed {file_path}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"    Unable to remove {file_path}. Reason: {e}\")\n",
    "\n",
    "\n",
    "        print(f\"    > Finished scanning {self.backup_dir}.\")  # Debugging print\n",
    "\n",
    "    def check_for_changes(self):\n",
    "        print(\"# Checking for changes between local and streamlit files.\")\n",
    "        pairs = []\n",
    "        grouped_paths = {}\n",
    "        changes_dict = {}\n",
    "\n",
    "        # Step 1: Group paths by their common prefix\n",
    "        for key, path in self.paths.items():\n",
    "            # if key does not contain an underscore, skip\n",
    "            if '_' not in key:\n",
    "                continue\n",
    "            prefix, suffix = key.rsplit('_', 1)\n",
    "            if prefix not in grouped_paths:\n",
    "                grouped_paths[prefix] = []\n",
    "            grouped_paths[prefix].append((suffix, path))\n",
    "\n",
    "        # Step 2: Create pairs from the grouped paths\n",
    "        for prefix, path_list in grouped_paths.items():\n",
    "            if len(path_list) > 1:\n",
    "                for i in range(len(path_list)):\n",
    "                    for j in range(i + 1, len(path_list)):\n",
    "                        suffix1, path1 = path_list[i]\n",
    "                        suffix2, path2 = path_list[j]\n",
    "                        pairs.append(((suffix1, path1), (suffix2, path2)))\n",
    "\n",
    "        # Step 3: Compare files in each pair and check for changes\n",
    "        for pair in pairs:\n",
    "            (suffix1, path1), (suffix2, path2) = pair\n",
    "            filename = path1.split('/')[-1]\n",
    "            \n",
    "            # Compare the files and capture changes\n",
    "            if filecmp.cmp(path1, path2, shallow=False):\n",
    "                print(f\"    No updates in {filename}.\")\n",
    "            else:\n",
    "                print(f\"    ! Changes detected in {filename}.\")\n",
    "                self.process_changes(filename, path1, path2)\n",
    "                if self.overwrite_local:\n",
    "                    shutil.copy2(path2, path1)\n",
    "                    print(f\"    * Updated {filename}.\")\n",
    "        \n",
    "        print('    > Check for changes completed.')\n",
    "        return changes_dict\n",
    "\n",
    "\n",
    "    def process_changes(self, filename, path1, path2):\n",
    "        if filename == '1_visit_schedule.csv':\n",
    "            self.process_visit_schedule_changes(filename, path1, path2)\n",
    "                \n",
    "    \n",
    "    def process_visit_schedule_changes(self, filename, path1, path2):\n",
    "        pids_needing_new_schedule = []\n",
    "        \n",
    "        for index, row in self.df_vs_s.iterrows():\n",
    "            pid = row['ParticipantID']\n",
    "\n",
    "            # NEW PARTICIPANT\n",
    "            if not pid in self.df_vs_l['ParticipantID'].values:\n",
    "                print(\"        New participant registered:\", pid)\n",
    "                pids_needing_new_schedule.append(pid)\n",
    "\n",
    "            # CHANGES TO EXISTING PARTICIPANT\n",
    "            else:\n",
    "                row_l = self.df_vs_l[self.df_vs_l['ParticipantID'] == pid]\n",
    "                row_s = self.df_vs_s[self.df_vs_s['ParticipantID'] == pid]\n",
    "                if not row_l.equals(row_s):\n",
    "                    print(\"        Visit information updated for participant:\", pid)\n",
    "                    pids_needing_new_schedule.append(pid)\n",
    "\n",
    "        if pids_needing_new_schedule:\n",
    "            print(\"    > Generating new email schedule for updated participants:\", pids_needing_new_schedule)\n",
    "            self.generate_email_schedule(pids_needing_new_schedule)\n",
    "\n",
    "\n",
    "    def check_missing_schedule(self): \n",
    "        \n",
    "        print(\"# Checking for missing schedules.\")\n",
    "        pids_needing_new_schedule = []               \n",
    "        # PARTICIPANT WITH MISSING EMAIL SCHEDULE\n",
    "        for pid in self.df_vs_l['ParticipantID'].values:\n",
    "            if pid not in pids_needing_new_schedule:\n",
    "                if not pid in self.df_es_l['ParticipantID'].values:\n",
    "                    print(\"    Participant missing email schedule:\", pid)\n",
    "                    pids_needing_new_schedule.append(pid)\n",
    "            \n",
    "        if len(pids_needing_new_schedule) > 0:\n",
    "            print(\"    > Generating new email schedule for participants:\", pids_needing_new_schedule)\n",
    "            self.generate_email_schedule(pids_needing_new_schedule)\n",
    "\n",
    "        self.missing_schedule_checked = True\n",
    "\n",
    "        if not len(pids_needing_new_schedule) > 0:\n",
    "            print(\"    > No missing schedules found.\")\n",
    "\n",
    "        return pids_needing_new_schedule\n",
    "\n",
    "    def generate_email_schedule(self, pids):\n",
    "        email_templates = {}\n",
    "        for index, row in self.df_et_l.iterrows():\n",
    "            email_templates[row['EmailCode']] = {\n",
    "                'Subject': row['Subject'],\n",
    "                'EmailBody': row['EmailBody'],\n",
    "                'Offset': row['Offset'],\n",
    "                'VisitNumber': row['VisitNumber'],\n",
    "            }\n",
    "        \n",
    "        print(\"    Loaded email codes:\", email_templates.keys())\n",
    "\n",
    "        rows_to_add = []\n",
    "        for pid in pids:\n",
    "            # Remove future scheduled emails for the participant before creating a new schedule\n",
    "            self.remove_future_scheduled_emails(pid)\n",
    "\n",
    "            # Generate new email schedule only if the EmailCode is not already present for this participant\n",
    "            participant_row = self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == pid]\n",
    "            existing_email_codes = self.df_es_l[self.df_es_l['ParticipantID'] == pid]['EmailCode'].tolist()\n",
    "\n",
    "            for email_code, info in email_templates.items():\n",
    "                if email_code not in existing_email_codes:\n",
    "                    rows_to_add.append({\n",
    "                        'ParticipantID': pid,\n",
    "                        'EmailCode': email_code,\n",
    "                        'ScheduledDate': self.calculate_scheduled_date(pid, info['VisitNumber'], info['Offset']),\n",
    "                        'UpdatedAt': self.date_time_now,\n",
    "                    })\n",
    "\n",
    "        new_rows = pd.DataFrame(rows_to_add)\n",
    "        self.df_es_l = pd.concat([self.df_es_l, new_rows], axis=0).reset_index(drop=True)\n",
    "        if self.overwrite_local:\n",
    "            self.df_es_l.to_csv(self.paths['email_schedule_local'], index=False)\n",
    "            self.__reload_dfs()\n",
    "            print(\"      * Added new email schedule for participants: \", pids)\n",
    "\n",
    "        # Check for existing participants to update their schedule with new templates\n",
    "        self.update_existing_participants_schedule(email_templates)\n",
    "\n",
    "    def update_existing_participants_schedule(self, email_templates):\n",
    "        \"\"\"\n",
    "        Update the email schedule for existing participants if there are new email templates added.\n",
    "        \"\"\"\n",
    "        print(\"    Checking for new email templates to update existing schedules...\")\n",
    "        \n",
    "        # Get all participants who already have a schedule\n",
    "        participants = self.df_es_l['ParticipantID'].unique()\n",
    "        \n",
    "        rows_to_add = []\n",
    "        for pid in participants:\n",
    "            existing_email_codes = self.df_es_l[self.df_es_l['ParticipantID'] == pid]['EmailCode'].tolist()\n",
    "            \n",
    "            # Check if any email templates are missing in the existing schedule\n",
    "            for email_code, info in email_templates.items():\n",
    "                if email_code not in existing_email_codes:\n",
    "                    # Only add if the email is not already scheduled\n",
    "                    rows_to_add.append({\n",
    "                        'ParticipantID': pid,\n",
    "                        'EmailCode': email_code,\n",
    "                        'ScheduledDate': self.calculate_scheduled_date(pid, info['VisitNumber'], info['Offset']),\n",
    "                        'UpdatedAt': self.date_time_now,\n",
    "                    })\n",
    "\n",
    "        # If new rows are added, update the email schedule\n",
    "        if rows_to_add:\n",
    "            new_rows = pd.DataFrame(rows_to_add)\n",
    "            self.df_es_l = pd.concat([self.df_es_l, new_rows], axis=0).reset_index(drop=True)\n",
    "            if self.overwrite_local:\n",
    "                self.df_es_l.to_csv(self.paths['email_schedule_local'], index=False)\n",
    "                self.__reload_dfs()\n",
    "            print(\"    * Updated existing participants' email schedules with new templates.\")\n",
    "\n",
    "\n",
    "    def calculate_scheduled_date(self, pid, visit_code, offset):\n",
    "        visit_date = self.df_vs_s.loc[self.df_vs_s['ParticipantID'] == pid, f\"{visit_code}_Date\"].values[0]\n",
    "        visit_date = datetime.strptime(visit_date, \"%Y-%m-%d\")       \n",
    "        scheduled_date = visit_date + timedelta(days=offset)\n",
    "        scheduled_date = scheduled_date.strftime(\"%Y-%m-%d\")\n",
    "        return scheduled_date\n",
    "    \n",
    "    # THESE ARE NEW AND NEED TO BE CHECKED\n",
    "\n",
    "    def check_emails_to_send_today(self):\n",
    "        print(\"# Checking for emails to be sent today.\")\n",
    "        today = datetime.now().strftime('%Y-%m-%d')\n",
    "        emails_to_send = self.df_es_l[self.df_es_l['ScheduledDate'] == today]\n",
    "        \n",
    "        if emails_to_send.empty:\n",
    "            print(\"    > No emails to be sent today.\")\n",
    "            return []\n",
    "        \n",
    "        print(f\"    > Found {len(emails_to_send)} emails to send today.\")\n",
    "        # print the emails \n",
    "        for _, row in emails_to_send.iterrows():\n",
    "            print(f\"        Participant {row['ParticipantID']} scheduled to receive email {row['EmailCode']} today.\")\n",
    "        return emails_to_send\n",
    "    \n",
    "    def create_email_dict(self, emails_to_send_today):\n",
    "        email_dict = {}\n",
    "        for _, row in emails_to_send_today.iterrows():\n",
    "            # check if participant is active\n",
    "            self.__reload_dfs()\n",
    "            if self.df_vs_l.loc[\n",
    "                self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'Active'].empty or \\\n",
    "                self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'Active'].values[0] not in ['True', True]:\n",
    "                print(f\"        Participant {row['ParticipantID']} is not active. Skipping email.\")\n",
    "            # check if email was already sent\n",
    "            elif not self.df_el_l.loc[(self.df_el_l['ParticipantID'] == row['ParticipantID']) & (self.df_el_l['EmailCode'] == row['EmailCode'])].empty:\n",
    "                print(f\"        Email {row['EmailCode']} for participant {row['ParticipantID']} was already sent. Skipping.\")\n",
    "            else:\n",
    "                # Check if the participant already exists in the dictionary\n",
    "                if row['ParticipantID'] not in email_dict:\n",
    "                    email_dict[row['ParticipantID']] = {}\n",
    "                \n",
    "                # Add the email details to the participant's dictionary\n",
    "                email_dict[row['ParticipantID']][row['EmailCode']] = { \n",
    "                    'ParticipantID': row['ParticipantID'],\n",
    "                    'EmailCode': row['EmailCode'],\n",
    "                    'ScheduledDate': row['ScheduledDate'],\n",
    "                    'UpdatedAt': row['UpdatedAt'],\n",
    "                    'Email': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'Email'].values[0],\n",
    "                    'FirstName': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'FirstName'].values[0],\n",
    "                    'Surname': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'Surname'].values[0],\n",
    "                    'Subject': self.df_et_l.loc[self.df_et_l['EmailCode'] == row['EmailCode'], 'Subject'].values[0],\n",
    "                    'EmailBody': self.df_et_l.loc[self.df_et_l['EmailCode'] == row['EmailCode'], 'EmailBody'].values[0],\n",
    "                    'V1_Date': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'V1_Date'].values[0],\n",
    "                    'V2_Date': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'V2_Date'].values[0],\n",
    "                    'V3_Date': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'V3_Date'].values[0],\n",
    "                    'V4_Date': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'V4_Date'].values[0],\n",
    "                    'V5_Date': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'V5_Date'].values[0],\n",
    "                    'V6_Date': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'V6_Date'].values[0],\n",
    "                    'V7_Date': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'V7_Date'].values[0],\n",
    "                    'V1_Time': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'V1_Time'].values[0],\n",
    "                    'V2_Time': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'V2_Time'].values[0],\n",
    "                    'V3_Time': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'V3_Time'].values[0],\n",
    "                    'V4_Time': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'V4_Time'].values[0],\n",
    "                    'V5_Time': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'V5_Time'].values[0],\n",
    "                    'V6_Time': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'V6_Time'].values[0],\n",
    "                    'V7_Time': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'V7_Time'].values[0],\n",
    "                }\n",
    "\n",
    "        return email_dict\n",
    "\n",
    "    \n",
    "    def check_attachments(self, email_code):\n",
    "\n",
    "        # Find value of column Attachments in df_et_l\n",
    "        attachment = self.df_et_l.loc[self.df_et_l['EmailCode'] == email_code, 'Attachments'].values[0]\n",
    "\n",
    "        # Check if the attachment is not None, 'None', or an empty string\n",
    "        if not pd.isna(attachment) and attachment not in ['False', False, 'None', 'none', 'NONE', '']:\n",
    "            # Check if it's a list of attachments (comma-separated)\n",
    "            if ',' in attachment:\n",
    "                attachment = [a.strip() for a in attachment.split(',')]  # Split and strip whitespace\n",
    "            else:\n",
    "                attachment = [attachment.strip()]  # Convert single attachment to list\n",
    "            # Prepend the path to each attachment\n",
    "            attachment = [os.path.join(self.paths['attachments'], a) for a in attachment]\n",
    "        else:\n",
    "            attachment = None\n",
    "\n",
    "        return attachment\n",
    "    \n",
    "    def check_calendar_event(self, email_code):\n",
    "        cal_event = self.df_et_l.loc[self.df_et_l['EmailCode'] == email_code, 'CalendarEvent'].values[0]\n",
    "        if cal_event in [0, '0']:\n",
    "            cal_event = False\n",
    "        else:\n",
    "            cal_event = True\n",
    "        \n",
    "        return cal_event\n",
    "    \n",
    "\n",
    "    def format_calendar_event(self, email_data):\n",
    "        # Find the corresponding visit number for the emal code\n",
    "        visit_number = self.df_et_l.loc[self.df_et_l['EmailCode'] == email_data['EmailCode'], 'VisitNumber'].values[0]\n",
    "        visit_number = visit_number[-1]  # Only keep the last character\n",
    "\n",
    "        subject = f\"UNITY Visit {visit_number} for {email_data['ParticipantID']}\"\n",
    "        description = f\"UNITY Visit {visit_number} for {email_data['ParticipantID']}\"\n",
    "        \n",
    "        # Combine date and time fields from email_data\n",
    "        start_date_str = email_data[f'V{visit_number}_Date']\n",
    "        start_time_str = email_data[f'V{visit_number}_Time']\n",
    "        \n",
    "        # Split the date and time strings into components\n",
    "        year, month, day = map(int, start_date_str.split('-'))  # Split and convert to integers\n",
    "        hour, minute = map(int, start_time_str.split(':'))  # Split and convert to integers\n",
    "\n",
    "        # Create a datetime object using the parsed components\n",
    "        start_time = datetime(year, month, day, hour, minute)\n",
    "        # Add 3 hours for the end time\n",
    "        end_time = start_time + timedelta(hours=3)\n",
    "\n",
    "        location = 'UCL'\n",
    "\n",
    "        # Generate the ICS attachment with formatted times\n",
    "        cal_attachment = self.emailer.create_ics_attachment(subject, description, start_time, end_time, location)\n",
    "\n",
    "        return cal_attachment\n",
    "\n",
    "\n",
    "\n",
    "    def send_email(self, pid, email_data):\n",
    "\n",
    "        email_code = email_data['EmailCode']\n",
    "        subject = email_data['Subject']\n",
    "        body = email_data['EmailBody']\n",
    "        escaped_email_body = re.sub(r\"{(?!\\w)\", \"{{\", body)\n",
    "        escaped_email_body = re.sub(r\"(?<=\\W)}\", \"}}\", escaped_email_body)\n",
    "        formatted_email_body = escaped_email_body.format(**email_data)\n",
    "        recipient = email_data['Email']\n",
    "        attachment = self.check_attachments(email_code)\n",
    "        calendar_event = self.check_calendar_event(email_code)\n",
    "        if calendar_event:\n",
    "            # add to attachment\n",
    "            cal_attachment = self.format_calendar_event(email_data)\n",
    "            if attachment:\n",
    "                attachment.append(cal_attachment)\n",
    "            else:\n",
    "                attachment = [cal_attachment]\n",
    "                              \n",
    "\n",
    "        status = self.emailer.send_email_from_outlook(sender=self.paths['email_sender'],\n",
    "                                            recepients=[recipient],\n",
    "                                            subject=subject,\n",
    "                                            email_body=formatted_email_body,\n",
    "                                            attachments_paths=attachment,  # Add if necessary\n",
    "                                            code=email_code)\n",
    "        \n",
    "        filtered_df = self.df_es_l.loc[\n",
    "                        (self.df_es_l[\"ParticipantID\"] == pid)\n",
    "                        & (self.df_es_l[\"EmailCode\"] == email_code),\n",
    "                        \"ScheduledDate\",\n",
    "                    ]\n",
    "\n",
    "        scheduled_for = None\n",
    "        if filtered_df.empty:\n",
    "            raise ValueError(\n",
    "                f\"No matching records found for ParticipantID: {pid} and EmailCode: {email_code}\"\n",
    "            )\n",
    "        else:\n",
    "            scheduled_for = filtered_df.values[0]\n",
    "        \n",
    "        email_receipt = {\n",
    "            'ParticipantID': pid,\n",
    "            'EmailCode': email_code,\n",
    "            'ScheduledFor': scheduled_for,\n",
    "            'SentAt': self.date_time_now,\n",
    "            'Status': status\n",
    "        }\n",
    "        time.sleep(2)\n",
    "        return email_receipt\n",
    "        \n",
    "    \n",
    "    def update_local_email_log(self, email_receipts):\n",
    "\n",
    "        dfx = pd.DataFrame(email_receipts)\n",
    "            \n",
    "        # concat to df_local_el\n",
    "        self.df_el_l = pd.concat([self.df_el_l, dfx], axis=0).reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "        # save to csv\n",
    "        if self.overwrite_local:\n",
    "            self.df_el_l.to_csv(self.paths['email_log_local'], index=False)\n",
    "            for email_receipt in email_receipts:\n",
    "                print(f\"     * Updated local email log for participant: {email_receipt['ParticipantID']}: {email_receipt['EmailCode']}.\")\n",
    "\n",
    "    def remove_future_scheduled_emails(self, participant_id):\n",
    "        \"\"\"\n",
    "        Remove future scheduled emails for the given participant ID.\n",
    "        \n",
    "        :param participant_id: The ID of the participant whose future emails should be removed.\n",
    "        \"\"\"\n",
    "        # Get today's date\n",
    "        today = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        # Filter out rows where the participant ID matches and the scheduled date is in the future\n",
    "        self.df_es_l = self.df_es_l[~((self.df_es_l['ParticipantID'] == participant_id) & (self.df_es_l['ScheduledDate'] > today))]\n",
    "        \n",
    "        # Optionally save changes back to the local file\n",
    "        if self.overwrite_local:\n",
    "            self.df_es_l.to_csv(self.paths['email_schedule_local'], index=False)\n",
    "            print(f\"     * Removed future scheduled emails for participant: {participant_id}\")\n",
    "\n",
    "    \n",
    "    def main(self):\n",
    "        print(\"REPORT TIME:\", self.date_time_now)\n",
    "        self.clear_old_backups()\n",
    "        self.backup_local_csvs()\n",
    "        changes = self.check_for_changes()\n",
    "        if not self.missing_schedule_checked:\n",
    "            self.check_missing_schedule()\n",
    "        emails_to_send_today = self.check_emails_to_send_today()\n",
    "\n",
    "        # # NEEDS TO BE CHECKED\n",
    "        email_receipts = []\n",
    "        if not emails_to_send_today.empty:\n",
    "            email_dict = self.create_email_dict(emails_to_send_today)\n",
    "            for pid, values in email_dict.items():\n",
    "                for email_code, email_data in values.items():\n",
    "                    email_receipt = self.send_email(pid, email_data)\n",
    "                    email_receipts.append(email_receipt)\n",
    "            if email_receipts:\n",
    "                self.update_local_email_log(email_receipts)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    paths = 'admin/paths.json'\n",
    "    scheduler = Scheduler(paths, backup_limit=60, overwrite_local=True)\n",
    "    scheduler.main()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tested scenarios:\n",
    "* Manually adding a new participant to streamlit visit schedule file. \n",
    "* Successfully copies over to local visit schedule. \n",
    "* Successfully generates email schedule.\n",
    "* Successfully sends emails to newly registered participants if they should receive email today.\n",
    "* Backup works. \n",
    "* It can send multiple emails to the same/different participants in one run. \n",
    "* If date is manually changed in streamlit file visit schedule, new schedule is generated. Emails scheduled for the future date are cleared from the current schedule and replaced with new emails. Emails scheduled for day in past are not cleared, because we don't want to regenerate the dates for the visit reminders that have already been happened.\n",
    "\n",
    "TO DO: \n",
    "* What doesn't work is when a new email is added to email templates, the email schedule for already registered participants is not updated.\n",
    "* Add logging / export print statements. \n",
    "* Do we want to default visit time to 3 hours or do we want this to be dynamically changing based on visit? \n",
    "* Integrate new emails template into the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ac8358d1b503c0f96e2d08601dd0f543e7a4e671455add481bb868c5f9844e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
