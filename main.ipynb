{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT TIME: 2024-10-17 13:26:00\n",
      "# Clearing old backups.\n",
      "    Starting to scan /data/jkuc/unity_scheduler/data/backup...\n",
      "    Scanning folder: /data/jkuc/unity_scheduler/data/backup\n",
      "    Scanning folder: /data/jkuc/unity_scheduler/data/backup/3_email_templates\n",
      "    Scanning folder: /data/jkuc/unity_scheduler/data/backup/4_email_log\n",
      "    Scanning folder: /data/jkuc/unity_scheduler/data/backup/2_email_schedule\n",
      "    Scanning folder: /data/jkuc/unity_scheduler/data/backup/1_visit_schedule\n",
      "    > Finished scanning /data/jkuc/unity_scheduler/data/backup.\n",
      "# Backing up local CSVs.\n",
      "    No changes detected in 4_email_log.csv, skipping backup.\n",
      "    No changes detected in 3_email_templates.csv, skipping backup.\n",
      "    No changes detected in 2_email_schedule.csv, skipping backup.\n",
      "    No changes detected in 1_visit_schedule.csv, skipping backup.\n",
      "    > Backup complete.\n",
      "# Checking for changes between local and streamlit files.\n",
      "    No updates in 1_visit_schedule.csv.\n",
      "    No updates in 3_email_templates.csv.\n",
      "    > Check for changes completed.\n",
      "# Checking for missing schedules.\n",
      "    > No missing schedules found.\n",
      "# Checking for emails to be sent today.\n",
      "    > Found 1 emails to send today.\n",
      "True\n",
      "Outlook email authentication successful.\n",
      "Email BOT01 from unity-project@ucl.ac.uk to ['joannakuc@ymail.com'] sent successfully!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import filecmp\n",
    "import csv\n",
    "import webbrowser\n",
    "from datetime import datetime, timedelta\n",
    "from O365 import Account, FileSystemTokenBackend, Message\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "\n",
    "class OutlookEmailer:\n",
    "\n",
    "    def __init__(self, creds_path):\n",
    "        \"\"\"\n",
    "        Initialize the OutlookEmailer by loading credentials from the given file.\n",
    "        \n",
    "        :param creds_path: Path to the credentials JSON file.\n",
    "        \"\"\"\n",
    "        self.creds_dict = self._load_creds(creds_path)\n",
    "\n",
    "    def _load_creds(self, path):\n",
    "        \"\"\"\n",
    "        Load credentials from the provided file path.\n",
    "        \n",
    "        :param path: Path to the credentials JSON file.\n",
    "        :return: A dictionary containing the credentials.\n",
    "        \"\"\"\n",
    "        with open(path) as file:\n",
    "            creds_data = json.load(file)\n",
    "\n",
    "        return {\n",
    "            'description': creds_data[\"outlook_description\"],\n",
    "            'client_secret': creds_data[\"outlook_client_secret\"],\n",
    "            'application_id': creds_data[\"outlook_application_id\"],\n",
    "            'shared_mailbox': creds_data[\"outlook_shared_mailbox\"],\n",
    "            'personal_mailbox': creds_data[\"outlook_personal_mailbox\"],\n",
    "            'tenant_id': creds_data[\"outlook_tenant_id\"]\n",
    "        }\n",
    "\n",
    "    def get_creds(self, creds_file_path):\n",
    "        \"\"\"\n",
    "        Get credentials by loading them from a specified path.\n",
    "        \n",
    "        :param creds_file_path: Path to the credentials JSON file.\n",
    "        :return: A dictionary containing the credentials.\n",
    "        \"\"\"\n",
    "        return self._load_creds(creds_file_path)\n",
    "\n",
    "    def load_attachments(self, folder_path='attachments'):\n",
    "        files = os.listdir(folder_path)\n",
    "        return {os.path.splitext(file)[0]: os.path.join(folder_path, file) for file in files}\n",
    "\n",
    "    def authenticate_outlook(self, mailbox='personal'):\n",
    "        credentials = (self.creds_dict['application_id'], self.creds_dict['client_secret'])\n",
    "        token_backend = FileSystemTokenBackend(token_path='.', token_filename='o365_token.txt')\n",
    "\n",
    "        # Determine which mailbox to use\n",
    "        if mailbox == 'shared':\n",
    "            main_resource = self.creds_dict['shared_mailbox']\n",
    "        else:\n",
    "            main_resource = self.creds_dict['personal_mailbox']\n",
    "        \n",
    "        # Create an Account object with the chosen mailbox\n",
    "        account = Account(credentials, token_backend=token_backend, main_resource=main_resource)\n",
    "\n",
    "        # Add 'Mail.Send' to the scopes\n",
    "        scopes = ['User.Read', 'Mail.Read', 'Mail.Send', 'Mail.Read.Shared', 'Mail.Send.Shared']\n",
    "\n",
    "        # Try to load the token from the file\n",
    "        if not account.is_authenticated:\n",
    "            # Get the authorization URL\n",
    "            url, _ = account.con.get_authorization_url(requested_scopes=scopes)\n",
    "\n",
    "            # Open the URL in a web browser\n",
    "            webbrowser.open(url)\n",
    "\n",
    "            # Prompt the user to manually copy the authentication URL\n",
    "            print(\"Please manually copy the authentication URL from the web browser and paste it below.\")\n",
    "            auth_url = input(\"Authentication URL: \")\n",
    "\n",
    "            # Authenticate with the provided URL and scopes\n",
    "            if account.authenticate(url=auth_url, scopes=scopes):\n",
    "                # Save the token to the file\n",
    "                \"Authentication successful. Token saved to 'o365_token.txt'.\"\n",
    "            else:\n",
    "                print(\"Authentication failed.\")\n",
    "                return None\n",
    "\n",
    "        return account\n",
    "\n",
    "\n",
    "    def send_email_from_outlook(self, sender, recepients, subject, email_body, attachments_paths, code=None):\n",
    "\n",
    "        account = self.authenticate_outlook(self.creds_dict)\n",
    "\n",
    "        if account is not None and account.is_authenticated:\n",
    "            print('Outlook email authentication successful.')\n",
    "\n",
    "            m = account.new_message()\n",
    "            m.sender.address = sender  # The shared mailbox\n",
    "            m.to.add(recepients)\n",
    "            m.subject = subject\n",
    "\n",
    "            # Check if attachments_paths is not None\n",
    "            if attachments_paths is not None:\n",
    "                # Loop over attachments paths\n",
    "                for path in attachments_paths:\n",
    "                    # Skip over None values\n",
    "                    if path is not None:\n",
    "                        # Add the attachment\n",
    "                        m.attachments.add(path)\n",
    "\n",
    "            m.body = email_body\n",
    "            m.send()\n",
    "\n",
    "            print(f\"Email {code} from {sender} to {recepients} sent successfully!\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Failed to send email. Authentication unsuccessful.\")\n",
    "            return False\n",
    "\n",
    "        #TODO: Figure out when authentication expires, and how to make it last longer?\n",
    "\n",
    "    def create_ics_attachment(subject, description, start_time, end_time, location, filename):\n",
    "    # Generate the ICS content as a string\n",
    "        ics_content = f\"\"\"BEGIN:VCALENDAR\n",
    "            VERSION:2.0\n",
    "            PRODID:-//Your Organization//NONSGML v1.0//EN\n",
    "            BEGIN:VEVENT\n",
    "            UID:{datetime.datetime.now().strftime('%Y%m%dT%H%M%SZ')}\n",
    "            DTSTAMP:{datetime.datetime.now().strftime('%Y%m%dT%H%M%SZ')}\n",
    "            DTSTART:{start_time.strftime('%Y%m%dT%H%M%SZ')}\n",
    "            DTEND:{end_time.strftime('%Y%m%dT%H%M%SZ')}\n",
    "            SUMMARY:{subject}\n",
    "            DESCRIPTION:{description}\n",
    "            LOCATION:{location}\n",
    "            END:VEVENT\n",
    "            END:VCALENDAR\n",
    "            \"\"\"\n",
    "\n",
    "        # Write ICS content to a file\n",
    "        ics_file_path = f\"{filename}.ics\"\n",
    "        with open(ics_file_path, 'w') as f:\n",
    "            f.write(ics_content)\n",
    "        \n",
    "        return ics_file_path\n",
    "    \n",
    "    \n",
    "    def is_valid_email(self, email):\n",
    "        email = email.lower()  \n",
    "        email_regex = r'^\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b$'\n",
    "        return re.match(email_regex, email) is not None\n",
    "    \n",
    "\n",
    "    def get_email_template(self, email_code, templates_df):\n",
    "        mask = templates_df[\"EmailCode\"].astype(str) == email_code\n",
    "        email_body = templates_df[mask]['EmailBody'].iloc[0]\n",
    "        subject = templates_df[mask]['Subject'].iloc[0]\n",
    "        escaped_email_body = re.sub(r\"{(?!\\w)\", \"{{\", email_body)\n",
    "        escaped_email_body = re.sub(r\"(?<=\\W)}\", \"}}\", escaped_email_body)\n",
    "        return subject, escaped_email_body\n",
    "\n",
    "    def send_reminders(self, email_list, email_code, templates_df):\n",
    "        if not email_list:\n",
    "            return\n",
    "\n",
    "        subject, email_body = self.get_email_template(email_code, templates_df)\n",
    "        \n",
    "        for email in email_list:\n",
    "            self.send_email_from_outlook(self.creds_dict, SENDER_EMAIL, [email], subject, email_body, attachments_paths=None, code=email_code)\n",
    "            self.google_sheet.attempt_request(self.google_sheet.update_column_value, 'Journalling Sign Ups', 5, \"Email\", email)\n",
    "            self.google_sheet.attempt_request(self.google_sheet.update_column_value, 'Journalling Sign Ups', 5, \"EmailCode\", email_code)\n",
    "            self.google_sheet.attempt_request(self.google_sheet.update_column_value, 'Journalling Sign Ups', 5, \"SentAt\", str(dt.datetime.now()))\n",
    "\n",
    "    def generate_src_tag(self, file_paths):\n",
    "        src_tags = {}\n",
    "        \n",
    "        for file_path in file_paths:\n",
    "            # Encode the image in base64\n",
    "            encoded_image = self.encode_image_base64(file_path)\n",
    "            \n",
    "            # Extract the file extension (without the dot)\n",
    "            file_extension = os.path.splitext(file_path)[1][1:]\n",
    "            \n",
    "            # Generate the filename (without the extension)\n",
    "            filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "            \n",
    "            # Generate the src tag\n",
    "            src_tag = f'<img src=\"data:image/{file_extension};base64,{encoded_image}\" alt=\"{filename} Image\" width=\"200\">'\n",
    "            \n",
    "            # Append the src tag to the dictionary\n",
    "            src_tags[filename] = src_tag\n",
    "        \n",
    "        return src_tags\n",
    "\n",
    "    def encode_image_base64(image_path):\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "        return encoded_string\n",
    "    \n",
    "\n",
    "    def find_file_with_extension(self, directory, filename_prefix):\n",
    "        # List all files in the given directory\n",
    "        files = os.listdir(directory)\n",
    "        \n",
    "        # Search for a file that starts with the given filename_prefix\n",
    "        for file in files:\n",
    "            if file.startswith(filename_prefix):\n",
    "                return file  # return the full filename including its extension\n",
    "        return None  # return None if no matching file was found\n",
    "\n",
    "    def read_emails_from_outlook(self, folder_name='Inbox', query=None, limit=10, mailbox='personal'):\n",
    "    # Authenticate with the specified mailbox\n",
    "        account = self.authenticate_outlook(mailbox=mailbox)\n",
    "        if not account or not account.is_authenticated:\n",
    "            print(\"Failed to authenticate Outlook account for reading emails.\")\n",
    "            return None\n",
    "\n",
    "        # Get the mailbox\n",
    "        if mailbox == 'personal':\n",
    "            mailbox = self.creds_dict[\"personal_mailbox\"]\n",
    "        elif mailbox == 'shared':\n",
    "            mailbox = self.creds_dict[\"shared_mailbox\"]\n",
    "\n",
    "        mailbox = account.mailbox(mailbox)\n",
    "\n",
    "        # Get the folder to read emails from (default is 'Inbox')\n",
    "        folder = mailbox.get_folder(folder_name) if folder_name != 'Inbox' else mailbox.inbox_folder()\n",
    "\n",
    "        # Query emails\n",
    "        try:\n",
    "            emails = folder.get_messages(limit=limit, query=query)\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving emails: {e}\")\n",
    "            return None\n",
    "\n",
    "        email_data = []\n",
    "        for message in emails:\n",
    "            email_info = {\n",
    "                'subject': message.subject,\n",
    "                'from': message.sender.address,\n",
    "                'to': [recipient.address for recipient in message.to],\n",
    "                'received': message.received,\n",
    "                'body': message.body,\n",
    "                'attachments': [attachment.name for attachment in message.attachments]\n",
    "            }\n",
    "            email_data.append(email_info)\n",
    "\n",
    "            # Attempt to mark emails as read\n",
    "            # try:\n",
    "            #     message.mark_as_read()\n",
    "            # except Exception as e:\n",
    "            #     print(f\"Error marking message as read (message subject: {message.subject}): {e}\")  # Print the specific error encountered\n",
    "            #     continue\n",
    "\n",
    "        return email_data\n",
    "\n",
    "class Scheduler:\n",
    "\n",
    "    def __init__(self, paths, backup_limit=60, overwrite_local=True):\n",
    "\n",
    "        self.paths = self.__load_paths(paths)\n",
    "        self.__reload_dfs()\n",
    "        \n",
    "        self.local_dir = self.paths['local_dir']\n",
    "        self.backup_dir = self.paths['backup_dir']\n",
    "        self.log_file = self.paths['log_file']\n",
    "\n",
    "        self.missing_schedule_checked = False\n",
    "        \n",
    "        self.emailer = OutlookEmailer(self.paths['creds'])\n",
    "\n",
    "        self.date_time_now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        self.date_time_now_fileformat = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        self.backup_limit = backup_limit\n",
    "        self.overwrite_local = overwrite_local\n",
    "        \n",
    "        self.dates = ['V1_Date', 'V2_Date', 'V3_Date', 'V4_Date', 'V5_Date', 'V6_Date', 'V7_Date']\n",
    "        self.times = ['V1_Time', 'V2_Time', 'V3_Time', 'V4_Time', 'V5_Time', 'V6_Time', 'V7_Time']\n",
    "\n",
    "        logging.basicConfig(\n",
    "            filename=self.log_file, \n",
    "            level=logging.INFO, \n",
    "            format='%(asctime)s - %(levelname)s - %(message)s', \n",
    "            datefmt='%Y-%m-%d %H:%M:%S'\n",
    "        )\n",
    "\n",
    "        # load dataframes\n",
    "    \n",
    "    def __reload_dfs(self):\n",
    "        # local\n",
    "        self.df_vs_l = pd.read_csv(self.paths['visit_schedule_local'])\n",
    "        self.df_es_l = pd.read_csv(self.paths['email_schedule_local'])\n",
    "        self.df_et_l = pd.read_csv(self.paths['email_templates_local'])\n",
    "        self.df_el_l = pd.read_csv(self.paths['email_log_local'])\n",
    "        # streamlit\n",
    "        self.df_vs_s = pd.read_csv(self.paths['visit_schedule_streamlit'])\n",
    "        self.df_et_s = pd.read_csv(self.paths['email_templates_streamlit'])\n",
    "    \n",
    "    def __load_paths(self, paths):\n",
    "        with open(paths, 'r') as f:\n",
    "            paths = json.load(f)\n",
    "        return paths\n",
    "\n",
    "    def backup_local_csvs(self):\n",
    "        print(\"# Backing up local CSVs.\")\n",
    "        if not os.path.exists(self.backup_dir):\n",
    "            os.makedirs(self.backup_dir)\n",
    "            \n",
    "        log_details = []\n",
    "        \n",
    "        for filename in os.listdir(self.local_dir):\n",
    "            if filename.endswith('.csv'):\n",
    "                subfolder_name = filename.rsplit('.', 1)[0]\n",
    "                subfolder_path = os.path.join(self.backup_dir, subfolder_name)\n",
    "                \n",
    "                if not os.path.exists(subfolder_path):\n",
    "                    os.makedirs(subfolder_path)\n",
    "\n",
    "                source_file_path = os.path.join(self.local_dir, filename)\n",
    "\n",
    "                # Get the most recent backup file in the subfolder (if any)\n",
    "                existing_backups = [f for f in os.listdir(subfolder_path) if f.endswith('.csv')]\n",
    "                existing_backups.sort(reverse=True)  # Sort backups by date\n",
    "\n",
    "                most_recent_backup = existing_backups[0] if existing_backups else None\n",
    "                most_recent_backup_path = os.path.join(subfolder_path, most_recent_backup) if most_recent_backup else None\n",
    "\n",
    "                # Compare the current file with the most recent backup (if any)\n",
    "                if most_recent_backup_path and filecmp.cmp(source_file_path, most_recent_backup_path, shallow=False):\n",
    "                    log_details.append(f\"    No changes detected in {filename}, skipping backup.\")\n",
    "                else:\n",
    "                    backup_filename = f\"{subfolder_name}_{self.date_time_now_fileformat}.csv\"\n",
    "                    backup_file_path = os.path.join(subfolder_path, backup_filename)\n",
    "                    if self.overwrite_local:\n",
    "                        shutil.copy2(source_file_path, backup_file_path)\n",
    "                    log_details.append(f\"    * Backed up {filename}.\")\n",
    "\n",
    "        # Write log details to the log file\n",
    "        with open(self.log_file, 'a') as log:\n",
    "            for detail in log_details:\n",
    "                log.write(detail + '\\n')\n",
    "                print(detail)\n",
    "        \n",
    "        print('    > Backup complete.')\n",
    "\n",
    "    def clear_old_backups(self):\n",
    "        print(\"# Clearing old backups.\")\n",
    "        print(f\"    Starting to scan {self.backup_dir}...\")  # Debugging print\n",
    "        pattern = re.compile(r\"(\\d{8})_(\\d{6})\\.csv$\")\n",
    "        for foldername, _, filenames in os.walk(self.backup_dir):\n",
    "            print(f\"    Scanning folder: {foldername}\")  # Debugging print\n",
    "            for filename in filenames:\n",
    "                match = pattern.search(filename)\n",
    "                if not match:\n",
    "                    print(f\"    Skipping: {filename}\")  # Debugging print for filenames that don't match the pattern\n",
    "                    continue\n",
    "                \n",
    "                date_str, time_str = match.groups()\n",
    "                \n",
    "                # Convert date and time strings to a datetime object\n",
    "                file_date = datetime.strptime(date_str + time_str, \"%Y%m%d%H%M%S\")\n",
    "                self.dtm = datetime.strptime(self.date_time_now_fileformat, \"%Y%m%d_%H%M%S\")\n",
    "                \n",
    "                # Check file age\n",
    "                if self.backup_limit == 0:\n",
    "                    # remove all files\n",
    "                    file_path = os.path.join(foldername, filename)\n",
    "                    try:\n",
    "                        os.remove(file_path)\n",
    "                        print(f\"    Removed {file_path}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"    Unable to remove {file_path}. Reason: {e}\")\n",
    "                elif (self.dtm - file_date).days > self.backup_limit:\n",
    "                    file_path = os.path.join(foldername, filename)\n",
    "                    try:\n",
    "                        os.remove(file_path)\n",
    "                        print(f\"    Removed {file_path}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"    Unable to remove {file_path}. Reason: {e}\")\n",
    "\n",
    "\n",
    "        print(f\"    > Finished scanning {self.backup_dir}.\")  # Debugging print\n",
    "\n",
    "    def check_for_changes(self):\n",
    "        print(\"# Checking for changes between local and streamlit files.\")\n",
    "        pairs = []\n",
    "        grouped_paths = {}\n",
    "        changes_dict = {}\n",
    "\n",
    "        # Step 1: Group paths by their common prefix\n",
    "        for key, path in self.paths.items():\n",
    "            # if key does not contain an underscore, skip\n",
    "            if '_' not in key:\n",
    "                continue\n",
    "            prefix, suffix = key.rsplit('_', 1)\n",
    "            if prefix not in grouped_paths:\n",
    "                grouped_paths[prefix] = []\n",
    "            grouped_paths[prefix].append((suffix, path))\n",
    "\n",
    "        # Step 2: Create pairs from the grouped paths\n",
    "        for prefix, path_list in grouped_paths.items():\n",
    "            if len(path_list) > 1:\n",
    "                for i in range(len(path_list)):\n",
    "                    for j in range(i + 1, len(path_list)):\n",
    "                        suffix1, path1 = path_list[i]\n",
    "                        suffix2, path2 = path_list[j]\n",
    "                        pairs.append(((suffix1, path1), (suffix2, path2)))\n",
    "\n",
    "        # Step 3: Compare files in each pair and check for changes\n",
    "        for pair in pairs:\n",
    "            (suffix1, path1), (suffix2, path2) = pair\n",
    "            filename = path1.split('/')[-1]\n",
    "            \n",
    "            # Compare the files and capture changes\n",
    "            if filecmp.cmp(path1, path2, shallow=False):\n",
    "                print(f\"    No updates in {filename}.\")\n",
    "            else:\n",
    "                print(f\"    ! Changes detected in {filename}.\")\n",
    "                self.process_changes(filename, path1, path2)\n",
    "                if self.overwrite_local:\n",
    "                    shutil.copy2(path2, path1)\n",
    "                    print(f\"    * Updated {filename}.\")\n",
    "        \n",
    "        print('    > Check for changes completed.')\n",
    "        return changes_dict\n",
    "\n",
    "    def process_changes(self, filename, path1, path2):\n",
    "        if filename == '1_visit_schedule.csv':\n",
    "            self.process_visit_schedule_changes(filename, path1, path2)\n",
    "                \n",
    "    \n",
    "    def process_visit_schedule_changes(self, filename, path1, path2):\n",
    "\n",
    "        pids_needing_new_schedule = []\n",
    "      \n",
    "        for index, row in self.df_vs_s.iterrows():\n",
    "            pid = row['ParticipantID']\n",
    "\n",
    "            # NEW PARTICIPANT\n",
    "            if not pid in self.df_vs_l['ParticipantID'].values:\n",
    "                print(\"        New participant registered:\", pid)\n",
    "                pids_needing_new_schedule.append(pid)\n",
    "\n",
    "            # CHANGES TO EXISTING PARTICIPANT\n",
    "            else:\n",
    "                row_l = self.df_vs_l[self.df_vs_l['ParticipantID'] == pid]\n",
    "                row_s = self.df_vs_s[self.df_vs_s['ParticipantID'] == pid]\n",
    "                if not row_l.equals(row_s):\n",
    "                    print(\"        Visit information updated for participant:\", pid)\n",
    "                    pids_needing_new_schedule.append(pid)\n",
    "\n",
    "    def check_missing_schedule(self): \n",
    "        \n",
    "        print(\"# Checking for missing schedules.\")\n",
    "        pids_needing_new_schedule = []               \n",
    "        # PARTICIPANT WITH MISSING EMAIL SCHEDULE\n",
    "        for pid in self.df_vs_l['ParticipantID'].values:\n",
    "            if pid not in pids_needing_new_schedule:\n",
    "                if not pid in self.df_es_l['ParticipantID'].values:\n",
    "                    print(\"    Participant missing email schedule:\", pid)\n",
    "                    pids_needing_new_schedule.append(pid)\n",
    "            \n",
    "        if len(pids_needing_new_schedule) > 0:\n",
    "            print(\"    > Generating new email schedule for participants:\", pids_needing_new_schedule)\n",
    "            self.generate_email_schedule(pids_needing_new_schedule)\n",
    "\n",
    "        self.missing_schedule_checked = True\n",
    "\n",
    "        if not len(pids_needing_new_schedule) > 0:\n",
    "            print(\"    > No missing schedules found.\")\n",
    "\n",
    "        return pids_needing_new_schedule\n",
    "\n",
    "    def generate_email_schedule(self, pids):\n",
    "\n",
    "        email_templates = {}\n",
    "        for index, row in self.df_et_l.iterrows():\n",
    "            email_templates[row['EmailCode']] = {'Subject': row['Subject'],\n",
    "                                                'EmailBody': row['EmailBody'],\n",
    "                                                'Offset': row['Offset'],\n",
    "                                                'VisitNumber': row['VisitNumber'],\n",
    "                                                }\n",
    "        \n",
    "        print(\"    Loaded email codes:\", email_templates.keys())\n",
    "\n",
    "        # First check if any rows with this ParticipantID exist in email_schedule local\n",
    "        if not self.df_es_l.loc[self.df_es_l['ParticipantID'].isin([pids])].empty:\n",
    "            # remove these rows\n",
    "            self.df_es_l = self.df_es_l.loc[~self.df_es_l['ParticipantID'].isin(pids)]\n",
    "            print(\"     * Removed existing email schedule for participants: \", pids)\n",
    "            if self.overwrite_local:\n",
    "                self.df_es_l.to_csv(self.paths['email_schedule_local'], index=False)\n",
    "                self.df_es_l.to_csv(self.paths['email_schedule_streamlit'], index=False)\n",
    "                print(\"     * Removed local + streamlit existing email schedule for participants: \", pids)\n",
    "\n",
    "        # Generate new email schedule\n",
    "        rows_to_add = []\n",
    "        for pid in pids:\n",
    "            participant_row = self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == pid]\n",
    "            for email_code, info in email_templates.items():\n",
    "                rows_to_add.append({\n",
    "                    'ParticipantID': pid,\n",
    "                    'EmailCode': email_code,\n",
    "                    'ScheduledDate': self.calculate_scheduled_date(pid, info['VisitNumber'], info['Offset']),\n",
    "                    'UpdatedAt': self.date_time_now,\n",
    "                })\n",
    "        new_rows = pd.DataFrame(rows_to_add)\n",
    "        self.df_es_l = pd.concat([self.df_es_l, new_rows], axis=0\n",
    "                                     ).reset_index(drop=True)\n",
    "        if self.overwrite_local:\n",
    "            self.df_es_l.to_csv(self.paths['email_schedule_local'], index=False)\n",
    "            self.df_es_l.to_csv(self.paths['email_schedule_streamlit'], index=False)\n",
    "            self.__reload_dfs()\n",
    "            print(\"     * Added new email schedule for participants locally + streamlit: \", pids)\n",
    "\n",
    "    def calculate_scheduled_date(self, pid, visit_code, offset):\n",
    "        visit_date = self.df_vs_s.loc[self.df_vs_s['ParticipantID'] == pid, f\"{visit_code}_Date\"].values[0]\n",
    "        visit_date = datetime.strptime(visit_date, \"%Y-%m-%d\")       \n",
    "        scheduled_date = visit_date + timedelta(days=offset)\n",
    "        scheduled_date = scheduled_date.strftime(\"%Y-%m-%d\")\n",
    "        return scheduled_date\n",
    "    \n",
    "    # THESE ARE NEW AND NEED TO BE CHECKED\n",
    "\n",
    "    def check_emails_to_send_today(self):\n",
    "        print(\"# Checking for emails to be sent today.\")\n",
    "        today = datetime.now().strftime('%Y-%m-%d')\n",
    "        emails_to_send = self.df_es_l[self.df_es_l['ScheduledDate'] == today]\n",
    "        \n",
    "        if emails_to_send.empty:\n",
    "            print(\"    > No emails to be sent today.\")\n",
    "            return []\n",
    "        \n",
    "        print(f\"    > Found {len(emails_to_send)} emails to send today.\")\n",
    "        return emails_to_send\n",
    "    \n",
    "    def create_email_dict(self, emails_to_send_today):\n",
    "\n",
    "        email_dict = {}\n",
    "        for _, row in emails_to_send_today.iterrows():\n",
    "            # check if participant is active\n",
    "            print(self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'Active'].values[0])\n",
    "            if self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'Active'].values[0] not in ['True', True] :\n",
    "                print(f\"    Participant {row['ParticipantID']} is not active. Skipping email.\")\n",
    "            else:\n",
    "                email_dict[row['ParticipantID']] = {\n",
    "                        'ParticipantID': row['ParticipantID'],\n",
    "                        'EmailCode': row['EmailCode'],\n",
    "                        'ScheduledDate': row['ScheduledDate'],\n",
    "                        'UpdatedAt': row['UpdatedAt'],\n",
    "                        'Email': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'Email'].values[0],\n",
    "                        'FirstName': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'FirstName'].values[0],\n",
    "                        'Surname': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'Surname'].values[0],\n",
    "                        'Subject': self.df_et_l.loc[self.df_et_l['EmailCode'] == row['EmailCode'], 'Subject'].values[0],\n",
    "                        'EmailBody': self.df_et_l.loc[self.df_et_l['EmailCode'] == row['EmailCode'], 'EmailBody'].values[0],\n",
    "                        'V1_Date': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'V1_Date'].values[0],\n",
    "                        'V2_Date': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'V2_Date'].values[0],\n",
    "                        'V3_Date': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'V3_Date'].values[0],\n",
    "                        'V4_Date': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'V4_Date'].values[0],\n",
    "                        'V5_Date': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'V5_Date'].values[0],\n",
    "                        'V6_Date': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'V6_Date'].values[0],\n",
    "                        'V7_Date': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'V7_Date'].values[0],\n",
    "                        'V1_Time': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'V1_Time'].values[0],\n",
    "                        'V2_Time': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'V2_Time'].values[0],\n",
    "                        'V3_Time': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'V3_Time'].values[0],\n",
    "                        'V4_Time': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'V4_Time'].values[0],\n",
    "                        'V5_Time': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'V5_Time'].values[0],\n",
    "                        'V6_Time': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'V6_Time'].values[0],\n",
    "                        'V7_Time': self.df_vs_l.loc[self.df_vs_l['ParticipantID'] == row['ParticipantID'], 'V7_Time'].values[0],\n",
    "                        \n",
    "                    }\n",
    "        return email_dict\n",
    "\n",
    "    \n",
    "    def main(self):\n",
    "        print(\"REPORT TIME:\", self.date_time_now)\n",
    "        self.clear_old_backups()\n",
    "        self.backup_local_csvs()\n",
    "        changes = self.check_for_changes()\n",
    "        if not self.missing_schedule_checked:\n",
    "            self.check_missing_schedule()\n",
    "        emails_to_send_today = self.check_emails_to_send_today()\n",
    "\n",
    "        # # NEEDS TO BE CHECKED\n",
    "        if not emails_to_send_today.empty:\n",
    "            email_data = self.create_email_dict(emails_to_send_today)\n",
    "            for pid, email_data in email_data.items():\n",
    "                email_code = email_data['EmailCode']\n",
    "                subject = email_data['Subject']\n",
    "                body = email_data['EmailBody']\n",
    "                escaped_email_body = re.sub(r\"{(?!\\w)\", \"{{\", body)\n",
    "                escaped_email_body = re.sub(r\"(?<=\\W)}\", \"}}\", escaped_email_body)\n",
    "                formatted_email_body = escaped_email_body.format(**email_data)\n",
    "                recipient = email_data['Email']\n",
    "                self.emailer.send_email_from_outlook(sender=self.paths['email_sender'],\n",
    "                                                    recepients=[recipient],\n",
    "                                                    subject=subject,\n",
    "                                                    email_body=formatted_email_body,\n",
    "                                                    attachments_paths=None,  # Add if necessary\n",
    "                                                    code=email_code)\n",
    "                \n",
    "                # After sending the email\n",
    "                new_log_entry = {\n",
    "                    'ParticipantID': pid,\n",
    "                    'EmailCode': email_code,\n",
    "                    'DateSent': self.date_time_now,\n",
    "                    'Status': 'Sent'\n",
    "                }\n",
    "        #         self.df_el_l = self.df_el_l.append(new_log_entry, ignore_index=True)\n",
    "\n",
    "        #         if self.overwrite_local:\n",
    "        #             self.df_el_l.to_csv(self.paths['email_log_local'], index=False)\n",
    "        #             self.df_el_l.to_csv(self.paths['email_log_streamlit'], index=False)\n",
    "        #             print(f\"    * Email log updated for Participant {row['ParticipantID']}.\")\n",
    "\n",
    "\n",
    "        # TODO: generate new email schedule for missing participants\n",
    "        # TODO: check if any emails are to be sent today\n",
    "        # TODO: if yes, send them\n",
    "        # TODO: update email_log_local and email_log_streamlit\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    paths = 'admin/paths.json'\n",
    "    scheduler = Scheduler(paths, backup_limit=60, overwrite_local=True)\n",
    "    scheduler.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ac8358d1b503c0f96e2d08601dd0f543e7a4e671455add481bb868c5f9844e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
